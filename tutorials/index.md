

In the following tutorials, we introduce the fundamental ideas of deep learning
and their realizations in _MXNet_
through a sequence of progressively more advanced tutorials.
Each tutorial introduces a set of of new concepts,
building upon the previous tutorials.
For example, our tutorial on linear regression
introduces fundamental ideas in supervised learning,
and the basic machinery for handling data and training models in MXNet.
In contrast, our tutorial on multilayer perceptrons focuses more on modeling,
introducing hidden representations, activations, and dropout regularization.
Finally, our tutorials on _convolutional neural networks_ (CNNs)
and _recurrent neural networks_ (RNNs),
focus on deeply on handling image data and sequential data respectively.

In addition to teaching the concepts,
each tutorial contains a high-quality working example,
accessible both as Jupyter notebooks and as clean code examples.
Feel free to grab these implementations as starting points
for building your own projects with _MXNet_.
